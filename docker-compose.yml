version: "3.9"
services:
  web:
    build:
      dockerfile: ./Dockerfile
      context: .
      args:
        NLTK_DATA: ${NLTK_DATA}
    env_file:
      - .env
    volumes:
      - .:/embedding_service/
      - ./.cache/torch/:/.cache/torch/
      - ./.cache/huggingface/:/.cache/huggingface/
      - ./data/nltk_data:/data/nltk_data
    ports:
      - "8000:8000"
    restart: on-failure 
    # uncomment to deploy on GPU
    #deploy:
    #  resources:
    #    reservations:
    #      devices:
    #        - driver: nvidia
    #          count: 1
    #          capabilities: [gpu]
    #TODO: multiple workers results in multiple instantiations of embedding model which won't fit on GPU
    #possible solution: https://github.com/tiangolo/fastapi/issues/2425#issuecomment-734790381
    command: sh -c "
      gunicorn --workers 1 -k uvicorn.workers.UvicornWorker app:app --bind 0.0.0.0:8000"

# TODO: validate if this is still required
volumes:
  tmpfs:
    driver: local
    driver_opts:
      o: "size=20g,uid=1000"
      device: tmpfs
      type: tmpfs