version: "3.9"
services:
  web:
    build:
      dockerfile: ./Dockerfile
      context: .
      args:
        NLTK_DATA: ${NLTK_DATA}
    env_file:
      - .env
    volumes:
      - .:/embedding_service/
      - ./.cache/torch/:/.cache/torch/
      - ./.cache/huggingface/:/.cache/huggingface/
      - ./data/nltk_data:/data/nltk_data
    ports:
      - "8000:8000"
    restart: on-failure 
    # if you do not want to use GPU, comment out the deploy section
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    # TODO: multiple workers results in multiple instantiations of embedding model which won't fit on GPU
    command: sh -c "
      gunicorn --workers 1 -k uvicorn.workers.UvicornWorker app:app --bind 0.0.0.0:8000"


volumes:
  tmpfs:
    driver: local
    driver_opts:
      o: "size=20g,uid=1000"
      device: tmpfs
      type: tmpfs